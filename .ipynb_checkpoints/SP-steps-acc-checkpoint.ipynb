{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPB-openACC-C-SP Implementation\n",
    "In this self-paced, hands-on lab, we will briefly explore some methods for OpenACC\n",
    "\n",
    "Qichao Hong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Before we begin, let's verify [WebSockets](http://en.wikipedia.org/wiki/WebSocket) are working on your system.  To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see get some output returned below the grey cell.  If not, please consult the [Self-paced Lab Troubleshooting FAQ](https://developer.nvidia.com/self-paced-labs-faq#Troubleshooting) to debug the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer should be three: 3\n"
     ]
    }
   ],
   "source": [
    "print (\"The answer should be three: \" + str(1+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the cell below to get some info about the GPUs on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 23 04:21:02 2017       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 780 Ti  Off  | 0000:01:00.0     N/A |                  N/A |\r\n",
      "| 26%   37C    P8    N/A /  N/A |    330MiB /  3017MiB |     N/A      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 780 Ti  Off  | 0000:02:00.0     N/A |                  N/A |\r\n",
      "| 26%   37C    P8    N/A /  N/A |      1MiB /  3020MiB |     N/A      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0                  Not Supported                                         |\r\n",
      "|    1                  Not Supported                                         |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU: Intel i7-4960x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<p class=\"hint_trigger\">If you have never before taken an IPython Notebook based self-paced lab from NVIDIA, click this green box.\n",
    "      <div class=\"toggle_container\"><div class=\"input_area box-flex1\"><div class=\\\"highlight\\\">The following video will explain the infrastructure we are using for this self-paced lab, as well as give some tips on it's usage.  If you've never taken a lab on this system before, it's highly encourage you watch this short video first.<br><br>\n",
    "<div align=\"center\"><iframe width=\"640\" height=\"390\" src=\"http://www.youtube.com/embed/ZMrDaLSFqpY\" frameborder=\"0\" allowfullscreen></iframe></div>\n",
    "<br>\n",
    "<h2 style=\"text-align:center;color:red;\">Attention Firefox Users</h2><div style=\"text-align:center; margin: 0px 25px 0px 25px;\">There is a bug with Firefox related to setting focus in any text editors embedded in this lab. Even though the cursor may be blinking in the text editor, focus for the keyboard may not be there, and any keys you press may be applying to the previously selected cell.  To work around this issue, you'll need to first click in the margin of the browser window (where there are no cells) and then in the text editor.  Sorry for this inconvenience, we're working on getting this fixed.</div></div></div></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to OpenACC\n",
    "\n",
    "Open-specification OpenACC directives are a straightforward way to accelerate existing Fortran and C applications. With OpenACC directives, you provide hints via compiler directives (or 'pragmas') to tell the compiler where -- and how -- it should parallelize compute-intensive code for execution on an accelerator. \n",
    "\n",
    "If you've done parallel programming using OpenMP, OpenACC is very similar: using directives, applications can be parallelized *incrementally*, with little or no change to the Fortran, C or C++ source. Debugging and code maintenance are easier. OpenACC directives are designed for *portability* across operating systems, host CPUs, and accelerators. You can use OpenACC directives with GPU accelerated libraries, explicit parallel programming languages (e.g., CUDA), MPI, and OpenMP, *all in the same program.*\n",
    "\n",
    "Watch the following short video introduction to OpenACC:\n",
    "\n",
    "<div align=\"center\"><iframe width=\"640\" height=\"390\" style=\"margin: 0 auto;\" src=\"http://www.youtube.com/embed/c9WYCFEt_Uo\" frameborder=\"0\" allowfullscreen></iframe></div>\n",
    "\n",
    "This hands-on lab walks you through a short sample of a scientific code, and demonstrates how you can employ OpenACC directives using a four-step process. You will make modifications to a simple C program, then compile and execute the newly enhanced code in each step. Along the way, hints and solution are provided, so you can check your work, or take a peek if you get lost.\n",
    "\n",
    "If you are confused now, or at any point in this lab, you can consult the <a href=\"#FAQ\">FAQ</a> located at the bottom of this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Characterize Your Application\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most difficult part of accelerator programming begins before the first line of code is written. If your program is not highly parallel, an accelerator or coprocesor won't be much use. Understanding the code structure is crucial if you are going to *identify opportunities* and *successfully* parallelize a piece of code. The first step in OpenACC programming then is to *characterize the application*. This includes:\n",
    "\n",
    "+ benchmarking the single-thread, CPU-only version of the application\n",
    "+ understanding the program structure and how data is passed through the call tree\n",
    "+ profiling the application and identifying computationally-intense \"hot spots\"\n",
    "    + which loop nests dominate the runtime?\n",
    "    + what are the minimum/average/maximum tripcounts through these loop nests?\n",
    "    + are the loop nests suitable for an accelerator?\n",
    "+ insuring that the algorithms you are considering for acceleration are *safely* parallel\n",
    "\n",
    "Note: what we've just said may sound a little scary, so please note that as parallel programming methods go OpenACC is really pretty friendly: think of it as a sandbox you can play in. Because OpenACC directives are incremental, you can add one or two directives at a time and see how things work: the compiler provides a *lot* of feedback. The right software plus good tools plus educational experiences like this one should put you on the path to successfully accelerating your programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Profiling and Benchmarking\n",
    "\n",
    "Before you start modifying code and adding OpenACC directives, you should benchmark the serial version of the program. To facilitate benchmarking after this and every other step in our parallel porting effort, we have built a timing routine around the main structure of our program -- a process we recommend you follow in your own efforts. Let's run the `SP` file without making any changes -- and see how fast the serial program executes. This will establish a baseline for future comparisons.  Execute the following two cells to compile and run the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f *.x *.o *~ mputil* ../common/*.o *.i *.cu *.ptx *.w2c.c *.w2c.h *.t *.B *.spin\n",
      "rm -f npbparams.h core\n",
      "make[1]: Entering directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "rm -f setparams setparams.h npbparams.h\n",
      "rm -f *~ *.o\n",
      "cc  -o setparams setparams.c\n",
      "make[1]: Leaving directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "../sys/setparams sp B\n",
      "cc  -c -I../common  -DCRPL_COMP=0 sp.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 initialize.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 exact_solution.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 exact_rhs.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 set_constants.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 adi.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 rhs.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 add.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 txinvr.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 error.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 verify.c\n",
      "cc  -c -I../common  -DCRPL_COMP=0 print_results.c\n",
      "cd ../common; cc  -c -I../common  c_timers.c\n",
      "cd ../common; cc  -c -I../common   -o wtime.o ../common/wtime.c\n",
      "cc  -o ./sp.B.x sp.o initialize.o exact_solution.o exact_rhs.o set_constants.o adi.o rhs.o add.o txinvr.o error.o verify.o print_results.o ../common/c_timers.o ../common/wtime.o  -lm\n"
     ]
    }
   ],
   "source": [
    "!cd ./NPB-acc/SP-seq/ && make clean && make SP CLASS=B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " NAS Parallel Benchmarks (NPB3.3-SER-C) - SP Benchmark\n",
      "\n",
      " No input file inputsp.data. Using compiled defaults\n",
      " Size:  102x 102x 102\n",
      " Iterations:  400    dt:   0.001000\n",
      "\n",
      " Time step    1\n",
      " Time step   20\n",
      " Time step   40\n",
      " Time step   60\n",
      " Time step   80\n",
      " Time step  100\n",
      " Time step  120\n",
      " Time step  140\n",
      " Time step  160\n",
      " Time step  180\n",
      " Time step  200\n",
      " Time step  220\n",
      " Time step  240\n",
      " Time step  260\n",
      " Time step  280\n",
      " Time step  300\n",
      " Time step  320\n",
      " Time step  340\n",
      " Time step  360\n",
      " Time step  380\n",
      " Time step  400\n",
      " Verification being performed for class B\n",
      " accuracy setting for epsilon =  1.0000000000000E-08\n",
      " Comparison of RMS-norms of residual\n",
      "           1 6.9032935799984E+01 6.9032935799980E+01 5.1669894843394E-14\n",
      "           2 3.0951344880842E+01 3.0951344880840E+01 7.6675593470184E-14\n",
      "           3 4.1033366470174E+01 4.1033366470170E+01 1.0407047262434E-13\n",
      "           4 3.8647690096039E+01 3.8647690096040E+01 3.8241066586602E-14\n",
      "           5 5.6434822725957E+01 5.6434822725960E+01 5.6405447956532E-14\n",
      " Comparison of RMS-norms of solution error\n",
      "           1 9.8100061901884E-03 9.8100061901880E-03 4.0494538769611E-14\n",
      "           2 1.0228279056704E-03 1.0228279056700E-03 3.9834968733392E-13\n",
      "           3 1.7205979116917E-03 1.7205979116920E-03 1.5110542631448E-13\n",
      "           4 1.6944794282311E-03 1.6944794282310E-03 8.5227195425935E-14\n",
      "           5 1.8474562639811E-02 1.8474562639810E-02 7.7559702986916E-14\n",
      " Verification Successful\n",
      "\n",
      "\n",
      " SP Benchmark Completed.\n",
      " Class           =                        B\n",
      " Size            =            102x 102x 102\n",
      " Iterations      =                      400\n",
      " Time in seconds =                   554.46\n",
      " Mop/s total     =                   640.28\n",
      " Operation type  =           floating point\n",
      " Verification    =               SUCCESSFUL\n",
      " Version         =                    3.3.1\n",
      " Compile date    =              23 May 2017\n",
      "\n",
      " Compile options:\n",
      "    CC           = (none)\n",
      "    CLINK        = (none)\n",
      "    C_LIB        = -lm\n",
      "    C_INC        = -I../common\n",
      "    CFLAGS       = (none)\n",
      "    CLINKFLAGS   = (none)\n",
      "    RAND         = (none)\n",
      "\n",
      "--------------------------------------\n",
      " Please send all errors/feedbacks to:\n",
      " Center for Manycore Programming\n",
      " cmp@aces.snu.ac.kr\n",
      " http://aces.snu.ac.kr\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "======== CPU profiling result (top down):\n",
      "Time(%)      Time  Name\n",
      " 100.00%    558.4s  main\n",
      " 99.55%   555.86s    adi\n",
      " 37.11%   207.25s    | compute_rhs\n",
      "  0.57%     3.19s    | | sqrt\n",
      " 20.77%   115.97s    | z_solve\n",
      "  2.50%    13.98s    | | tzetar\n",
      "  0.04%     200ms    | | lhsinitj\n",
      " 19.20%   107.19s    | y_solve\n",
      "  1.10%     6.12s    | | pinvr\n",
      "  0.03%     140ms    | | lhsinitj\n",
      " 18.74%   104.66s    | x_solve\n",
      "  1.10%     6.12s    | | ninvr\n",
      "  0.03%     170ms    | | lhsinit\n",
      "  1.88%    10.47s    | add\n",
      "  1.85%    10.32s    | txinvr\n",
      "  0.21%      1.2s    initialize\n",
      "  0.19%     1.04s    | exact_solution\n",
      "  0.12%     680ms    exact_rhs\n",
      "  0.05%     260ms    | exact_solution\n",
      "  0.12%     650ms    verify\n",
      "  0.09%     520ms    | compute_rhs\n",
      "  0.02%     110ms    | error_norm\n",
      "  0.02%      90ms    | | exact_solution\n",
      "  0.00%      20ms    | rhs_norm\n",
      "  0.00%      10ms    printf\n",
      "  0.00%      10ms      vfprintf\n",
      "  0.00%      10ms        _IO_file_xsputn\n",
      "  0.00%      10ms          _IO_do_write\n",
      "  0.00%      10ms            _IO_file_write\n",
      "  0.00%      10ms              write\n",
      "\n",
      "======== Data collected at 100Hz frequency\n"
     ]
    }
   ],
   "source": [
    "!pgprof --cpu-profiling on --cpu-profiling-mode top-down ./NPB-acc/SP-seq/sp.B.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Checking/Keeping a Record\n",
    "\n",
    "*After each step*, we will record the results from our benchmarking and correctness tests in a table like this one: \n",
    "\n",
    "|Step| Execution       | ExecutionTime (s)     | Speedup vs. 1 CPU Thread       | Correct? | Programming Time |\n",
    "|:--:| --------------- | ---------------------:| ------------------------------:|:--------:| -----------------|\n",
    "|1   | CPU 1 thread    | 554.46           |                                | Yes      |                |  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see x_solve(), y_solve(), z_solve(), and compute_rhs() need the most time to compute. So we will work mainly on these functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Add Compute Directives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things need to to before you add #pragma ...\n",
    "    1. Initiate the GPU\n",
    "        acc_init(acc_device_default);\n",
    "    2. Create the variables on GPU needed to run\n",
    "        #pragma acc data create(u,us,vs,ws,qs,rho_i,speed,square,forcing,rhs)\n",
    "        {\n",
    "            ...\n",
    "         }\n",
    "    3. In SP, these functions will make changes to array u[], forcing[], . If we don't updates it on GPU, we will get wrong result. \n",
    "        initialize(), exact_rhs().\n",
    "        \n",
    "        Add #pragma acc update device(var) at the end of the function to update relative variable in GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We mainly worked on x_solve, y_solve,  z_solve , and compute_rhs. We add compute directives to these for loops inside these three functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In x_solve , y_solve, z_solve, and compute_rhs:\n",
    "First, to run these functions in GPU, we need to feed the GPU the data it needs. And create some variables that are not in GPU to compute.\n",
    "\n",
    "```\n",
    "#pragma acc data present(rho_i,u,qs,rhs,square) create(lhsX,fjacX,njacX)\n",
    "{\n",
    "    ...\n",
    "}\n",
    "```\n",
    "##### Because GPU cannot directly call these functions,hsinit(int ni, int nj) and lhsinitj(int nj, int ni), we hardcode into x_solve, y_solve, and z_solve\n",
    "\n",
    "We see all the for loops are doing simple arithmatic action to some size of 5D arrays we can simply add \"#pragma acc parallel loop #\" before the nesty loops to make them parallel (each loop is independent).\n",
    "\n",
    "```\n",
    "#pragma acc parallel loop present(rhs)\n",
    "  for (k = 1; k <= nz2; k++) {\n",
    "    for (j = 1; j <= ny2; j++) {\n",
    "      for (i = 1; i <= nx2; i++) {\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f *.x *.o *~ mputil* ../common/*.o *.i *.cu *.ptx *.w2c.c *.w2c.h *.t *.B *.spin\n",
      "rm -f npbparams.h core\n",
      "make[1]: Entering directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "rm -f setparams setparams.h npbparams.h\n",
      "rm -f *~ *.o\n",
      "cc  -o setparams setparams.c\n",
      "make[1]: Leaving directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "../sys/setparams sp B\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 sp.c\n",
      "main:\n",
      "    199, Generating create(forcing[:][:][:][:],qs[:][:][:],rho_i[:][:][:],rhs[:][:][:][:],speed[:][:][:],square[:][:][:],u[:][:][:][:],us[:][:][:],vs[:][:][:],ws[:][:][:])\n",
      "    204, Generating update device(forcing[:][:][:][:])\n",
      "    210, Generating update device(u[:][:][:][:])\n",
      "    214, Generating update device(u[:][:][:][:])\n",
      "    228, Generating update self(u[:][:][:][:])\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 initialize.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 exact_solution.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 exact_rhs.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 set_constants.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 adi.c\n",
      "ninvr:\n",
      "     83, Generating present(rhs[:][:][:][:])\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "         84, #pragma acc loop gang /* blockIdx.x */\n",
      "         85, #pragma acc loop seq\n",
      "         86, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     85, Loop is parallelizable\n",
      "     86, Loop is parallelizable\n",
      "pinvr:\n",
      "    112, Generating present(rhs[:][:][:][:])\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        113, #pragma acc loop gang /* blockIdx.x */\n",
      "        114, #pragma acc loop seq\n",
      "        115, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    114, Loop is parallelizable\n",
      "    115, Loop is parallelizable\n",
      "tzetar:\n",
      "    143, Generating present(qs[:][:][:],rhs[:][:][:][:],speed[:][:][:],u[:][:][:][:],us[:][:][:],vs[:][:][:],ws[:][:][:])\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        144, #pragma acc loop gang /* blockIdx.x */\n",
      "        145, #pragma acc loop seq\n",
      "        146, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    145, Loop is parallelizable\n",
      "    146, Loop is parallelizable\n",
      "x_solve:\n",
      "    197, Generating create(lhsX[:][:][:][:],lhsmX[:][:][:][:],lhspX[:][:][:][:])\n",
      "         Generating present(rho_i[:][:][:])\n",
      "         Generating create(rhonX[:][:][:],rhsX[:][:][:][:])\n",
      "         Generating present(rhs[:][:][:][:],speed[:][:][:],us[:][:][:])\n",
      "    200, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        201, #pragma acc loop gang /* blockIdx.x */\n",
      "        202, #pragma acc loop seq\n",
      "        203, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    202, Loop is parallelizable\n",
      "    203, Loop is parallelizable\n",
      "    213, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        214, #pragma acc loop gang /* blockIdx.x */\n",
      "        215, #pragma acc loop seq\n",
      "        216, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    215, Loop is parallelizable\n",
      "    216, Loop is parallelizable\n",
      "    239, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        240, #pragma acc loop gang /* blockIdx.x */\n",
      "        241, #pragma acc loop seq\n",
      "        242, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "        248, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    241, Loop is parallelizable\n",
      "    242, Loop is parallelizable\n",
      "    248, Loop is parallelizable\n",
      "    265, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        266, #pragma acc loop gang /* blockIdx.x */\n",
      "        267, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    267, Loop is parallelizable\n",
      "    279, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        280, #pragma acc loop gang /* blockIdx.x */\n",
      "        281, #pragma acc loop seq\n",
      "        282, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    281, Loop is parallelizable\n",
      "    282, Loop is parallelizable\n",
      "    293, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        294, #pragma acc loop gang /* blockIdx.x */\n",
      "        295, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    295, Loop is parallelizable\n",
      "    311, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        312, #pragma acc loop gang /* blockIdx.x */\n",
      "        313, #pragma acc loop seq\n",
      "        314, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    313, Loop is parallelizable\n",
      "    314, Loop is parallelizable\n",
      "    336, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        337, #pragma acc loop gang /* blockIdx.x */\n",
      "        338, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "        339, #pragma acc loop seq\n",
      "    338, Loop is parallelizable\n",
      "    339, Loop carried dependence of lhsX,rhsX prevents parallelization\n",
      "         Loop carried backward dependence of lhsX,rhsX prevents vectorization\n",
      "    384, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        385, #pragma acc loop gang /* blockIdx.x */\n",
      "        386, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    386, Loop is parallelizable\n",
      "    426, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        427, #pragma acc loop gang /* blockIdx.x */\n",
      "        428, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "        429, #pragma acc loop seq\n",
      "    428, Loop is parallelizable\n",
      "    429, Loop carried dependence of lhsmX,lhspX,rhsX prevents parallelization\n",
      "         Loop carried backward dependence of lhsmX,lhspX,rhsX prevents vectorization\n",
      "    465, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        466, #pragma acc loop gang /* blockIdx.x */\n",
      "        467, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    467, Loop is parallelizable\n",
      "    500, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        501, #pragma acc loop gang /* blockIdx.x */\n",
      "        502, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    502, Loop is parallelizable\n",
      "    519, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        520, #pragma acc loop gang /* blockIdx.x */\n",
      "        521, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "        522, #pragma acc loop seq\n",
      "    521, Loop is parallelizable\n",
      "    522, Loop carried dependence of rhsX prevents parallelization\n",
      "         Loop carried backward dependence of rhsX prevents vectorization\n",
      "    554, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        555, #pragma acc loop gang /* blockIdx.x */\n",
      "        556, #pragma acc loop seq\n",
      "        557, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    556, Loop is parallelizable\n",
      "    557, Loop is parallelizable\n",
      "y_solve:\n",
      "    589, Generating create(lhsY[:][:][:][:],lhsmY[:][:][:][:],lhspY[:][:][:][:])\n",
      "         Generating present(rho_i[:][:][:])\n",
      "         Generating create(rhoqY[:][:][:])\n",
      "         Generating present(rhs[:][:][:][:],speed[:][:][:],vs[:][:][:])\n",
      "    591, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        592, #pragma acc loop gang /* blockIdx.x */\n",
      "        593, #pragma acc loop seq\n",
      "        594, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    593, Loop is parallelizable\n",
      "    594, Loop is parallelizable\n",
      "    618, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        619, #pragma acc loop gang /* blockIdx.x */\n",
      "        620, #pragma acc loop seq\n",
      "        621, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "        627, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    620, Loop is parallelizable\n",
      "    621, Loop is parallelizable\n",
      "    627, Loop is parallelizable\n",
      "    643, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        644, #pragma acc loop gang /* blockIdx.x */\n",
      "        645, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    645, Loop is parallelizable\n",
      "    657, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        658, #pragma acc loop gang /* blockIdx.x */\n",
      "        659, #pragma acc loop seq\n",
      "        660, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    659, Loop is parallelizable\n",
      "    660, Loop is parallelizable\n",
      "    671, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        672, #pragma acc loop gang /* blockIdx.x */\n",
      "        673, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    673, Loop is parallelizable\n",
      "    688, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        689, #pragma acc loop gang /* blockIdx.x */\n",
      "        690, #pragma acc loop seq\n",
      "        691, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    690, Loop is parallelizable\n",
      "    691, Loop is parallelizable\n",
      "    710, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        711, #pragma acc loop gang /* blockIdx.x */\n",
      "        712, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "        713, #pragma acc loop seq\n",
      "    712, Loop is parallelizable\n",
      "    713, Loop carried dependence of lhsY,rhs prevents parallelization\n",
      "         Loop carried backward dependence of lhsY,rhs prevents vectorization\n",
      "    759, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        760, #pragma acc loop gang /* blockIdx.x */\n",
      "        761, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    761, Loop is parallelizable\n",
      "    801, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        802, #pragma acc loop gang /* blockIdx.x */\n",
      "        803, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "        804, #pragma acc loop seq\n",
      "    803, Loop is parallelizable\n",
      "    804, Loop carried dependence of lhsmY,lhspY,rhs prevents parallelization\n",
      "         Loop carried backward dependence of lhsmY,lhspY,rhs prevents vectorization\n",
      "    839, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        840, #pragma acc loop gang /* blockIdx.x */\n",
      "        841, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    841, Loop is parallelizable\n",
      "    874, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        875, #pragma acc loop gang /* blockIdx.x */\n",
      "        876, #pragma acc loop seq\n",
      "        877, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    876, Loop is parallelizable\n",
      "    877, Loop is parallelizable\n",
      "    889, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        890, #pragma acc loop gang /* blockIdx.x */\n",
      "        891, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "        892, #pragma acc loop seq\n",
      "    891, Loop is parallelizable\n",
      "    892, Loop carried dependence of rhs prevents parallelization\n",
      "         Loop carried backward dependence of rhs prevents vectorization\n",
      "z_solve:\n",
      "    944, Generating create(lhsZ[:][:][:][:],lhsmZ[:][:][:][:],lhspZ[:][:][:][:])\n",
      "         Generating present(rho_i[:][:][:])\n",
      "         Generating create(rhosZ[:][:][:])\n",
      "         Generating present(rhs[:][:][:][:],speed[:][:][:],ws[:][:][:])\n",
      "    947, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        948, #pragma acc loop gang /* blockIdx.x */\n",
      "        949, #pragma acc loop seq\n",
      "        950, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    949, Loop is parallelizable\n",
      "    950, Loop is parallelizable\n",
      "    974, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        975, #pragma acc loop gang /* blockIdx.x */\n",
      "        976, #pragma acc loop seq\n",
      "        977, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    976, Loop is parallelizable\n",
      "    977, Loop is parallelizable\n",
      "    985, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        986, #pragma acc loop gang /* blockIdx.x */\n",
      "        987, #pragma acc loop seq\n",
      "        988, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    987, Loop is parallelizable\n",
      "    988, Loop is parallelizable\n",
      "   1003, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1004, #pragma acc loop gang /* blockIdx.x */\n",
      "       1005, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1005, Loop is parallelizable\n",
      "   1019, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1020, #pragma acc loop gang /* blockIdx.x */\n",
      "       1021, #pragma acc loop seq\n",
      "       1022, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1021, Loop is parallelizable\n",
      "   1022, Loop is parallelizable\n",
      "   1032, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1033, #pragma acc loop gang /* blockIdx.x */\n",
      "       1034, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1034, Loop is parallelizable\n",
      "   1051, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1052, #pragma acc loop gang /* blockIdx.x */\n",
      "       1053, #pragma acc loop seq\n",
      "       1054, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1053, Loop is parallelizable\n",
      "   1054, Loop is parallelizable\n",
      "   1073, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1074, #pragma acc loop gang /* blockIdx.x */\n",
      "       1075, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "       1076, #pragma acc loop seq\n",
      "   1075, Loop is parallelizable\n",
      "   1076, Loop carried dependence of lhsZ,rhs prevents parallelization\n",
      "         Loop carried backward dependence of lhsZ,rhs prevents vectorization\n",
      "   1122, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1123, #pragma acc loop gang /* blockIdx.x */\n",
      "       1124, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1124, Loop is parallelizable\n",
      "   1164, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1165, #pragma acc loop gang /* blockIdx.x */\n",
      "       1166, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "       1167, #pragma acc loop seq\n",
      "   1166, Loop is parallelizable\n",
      "   1167, Loop carried dependence of lhsmZ,lhspZ,rhs prevents parallelization\n",
      "         Loop carried backward dependence of lhsmZ,lhspZ,rhs prevents vectorization\n",
      "   1202, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1203, #pragma acc loop gang /* blockIdx.x */\n",
      "       1204, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1204, Loop is parallelizable\n",
      "   1238, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1239, #pragma acc loop gang /* blockIdx.x */\n",
      "       1240, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1240, Loop is parallelizable\n",
      "   1262, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1263, #pragma acc loop gang /* blockIdx.x */\n",
      "       1264, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "       1265, #pragma acc loop seq\n",
      "   1264, Loop is parallelizable\n",
      "   1265, Loop carried dependence of rhs prevents parallelization\n",
      "         Loop carried backward dependence of rhs prevents vectorization\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 rhs.c\n",
      "compute_rhs:\n",
      "     77, Generating present(forcing[:][:][:][:],qs[:][:][:],rho_i[:][:][:],rhs[:][:][:][:],speed[:][:][:],square[:][:][:],u[:][:][:][:],us[:][:][:],vs[:][:][:],ws[:][:][:])\n",
      "     80, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "         81, #pragma acc loop gang /* blockIdx.x */\n",
      "         82, #pragma acc loop seq\n",
      "         83, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     82, Loop is parallelizable\n",
      "     83, Loop is parallelizable\n",
      "    109, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        110, #pragma acc loop gang /* blockIdx.x */\n",
      "        111, #pragma acc loop seq\n",
      "        112, #pragma acc loop seq\n",
      "        113, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    111, Loop is parallelizable\n",
      "    112, Loop is parallelizable\n",
      "    113, Loop is parallelizable\n",
      "    123, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        124, #pragma acc loop gang /* blockIdx.x */\n",
      "        125, #pragma acc loop seq\n",
      "        126, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    125, Loop is parallelizable\n",
      "    126, Loop is parallelizable\n",
      "    170, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        171, #pragma acc loop gang /* blockIdx.x */\n",
      "        172, #pragma acc loop seq\n",
      "        173, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    172, Loop is parallelizable\n",
      "    173, Loop is parallelizable\n",
      "    181, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        182, #pragma acc loop gang /* blockIdx.x */\n",
      "        183, #pragma acc loop seq\n",
      "        184, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    183, Loop is parallelizable\n",
      "    184, Loop is parallelizable\n",
      "    192, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        193, #pragma acc loop gang /* blockIdx.x */\n",
      "        194, #pragma acc loop seq\n",
      "        195, #pragma acc loop seq\n",
      "        196, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    194, Loop is parallelizable\n",
      "    195, Loop is parallelizable\n",
      "    196, Loop is parallelizable\n",
      "    207, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        208, #pragma acc loop gang /* blockIdx.x */\n",
      "        209, #pragma acc loop seq\n",
      "        210, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    209, Loop is parallelizable\n",
      "    210, Loop is parallelizable\n",
      "    219, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        220, #pragma acc loop gang /* blockIdx.x */\n",
      "        221, #pragma acc loop seq\n",
      "        222, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    221, Loop is parallelizable\n",
      "    222, Loop is parallelizable\n",
      "    232, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        233, #pragma acc loop gang /* blockIdx.x */\n",
      "        234, #pragma acc loop seq\n",
      "        235, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    234, Loop is parallelizable\n",
      "    235, Loop is parallelizable\n",
      "    279, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        280, #pragma acc loop gang /* blockIdx.x */\n",
      "        281, #pragma acc loop seq\n",
      "        282, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    281, Loop is parallelizable\n",
      "    282, Loop is parallelizable\n",
      "    290, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        291, #pragma acc loop gang /* blockIdx.x */\n",
      "        292, #pragma acc loop seq\n",
      "        293, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    292, Loop is parallelizable\n",
      "    293, Loop is parallelizable\n",
      "    301, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        302, #pragma acc loop gang /* blockIdx.x */\n",
      "        303, #pragma acc loop seq\n",
      "        304, #pragma acc loop seq\n",
      "        305, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    303, Loop is parallelizable\n",
      "    304, Loop is parallelizable\n",
      "    305, Loop is parallelizable\n",
      "    316, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        317, #pragma acc loop gang /* blockIdx.x */\n",
      "        318, #pragma acc loop seq\n",
      "        319, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    318, Loop is parallelizable\n",
      "    319, Loop is parallelizable\n",
      "    328, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        329, #pragma acc loop gang /* blockIdx.x */\n",
      "        330, #pragma acc loop seq\n",
      "        331, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    330, Loop is parallelizable\n",
      "    331, Loop is parallelizable\n",
      "    341, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        342, #pragma acc loop gang /* blockIdx.x */\n",
      "        343, #pragma acc loop seq\n",
      "        344, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    343, Loop is parallelizable\n",
      "    344, Loop is parallelizable\n",
      "    387, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        388, #pragma acc loop gang /* blockIdx.x */\n",
      "        389, #pragma acc loop seq\n",
      "        390, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    389, Loop is parallelizable\n",
      "    390, Loop is parallelizable\n",
      "    398, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        399, #pragma acc loop gang /* blockIdx.x */\n",
      "        400, #pragma acc loop seq\n",
      "        401, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    400, Loop is parallelizable\n",
      "    401, Loop is parallelizable\n",
      "    409, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        410, #pragma acc loop gang /* blockIdx.x */\n",
      "        411, #pragma acc loop seq\n",
      "        412, #pragma acc loop seq\n",
      "        413, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    411, Loop is parallelizable\n",
      "    412, Loop is parallelizable\n",
      "    413, Loop is parallelizable\n",
      "    424, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        425, #pragma acc loop gang /* blockIdx.x */\n",
      "        426, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    426, Loop is parallelizable\n",
      "    453, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        454, #pragma acc loop gang /* blockIdx.x */\n",
      "        455, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    455, Loop is parallelizable\n",
      "    475, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        476, #pragma acc loop gang /* blockIdx.x */\n",
      "        477, #pragma acc loop seq\n",
      "        478, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    477, Loop is parallelizable\n",
      "    478, Loop is parallelizable\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 add.c\n",
      "add:\n",
      "     70, Generating present(rhs[:][:][:][:],u[:][:][:][:])\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "         71, #pragma acc loop gang /* blockIdx.x */\n",
      "         72, #pragma acc loop seq\n",
      "         73, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     72, Loop is parallelizable\n",
      "     73, Loop is parallelizable\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 txinvr.c\n",
      "txinvr:\n",
      "     71, Generating present(qs[:][:][:],rho_i[:][:][:],rhs[:][:][:][:],speed[:][:][:],us[:][:][:],vs[:][:][:],ws[:][:][:])\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "         72, #pragma acc loop gang /* blockIdx.x */\n",
      "         73, #pragma acc loop seq\n",
      "         74, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     73, Loop is parallelizable\n",
      "     74, Loop is parallelizable\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 error.c\n",
      "rhs_norm:\n",
      "    114, Generating update self(rhs[:][:][:][:])\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 verify.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 print_results.c\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium c_timers.c\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium  -o wtime.o ../common/wtime.c\n",
      "pgcc -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -o ./sp.B.x sp.o initialize.o exact_solution.o exact_rhs.o set_constants.o adi.o rhs.o add.o txinvr.o error.o verify.o print_results.o ../common/c_timers.o ../common/wtime.o  -lm\n"
     ]
    }
   ],
   "source": [
    "!cd ./NPB-acc/SP-step1/ && make clean && make CC=pgcc CLASS=B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get any error please check your work and try re-compilling.\n",
    "\n",
    "### We can see the detials about how compiler handle the loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " NAS Parallel Benchmarks (NPB3.3-ACC) - SP Benchmark\n",
      "\n",
      " No input file inputsp.data. Using compiled defaults\n",
      " Size:  102x 102x 102\n",
      " Iterations:  400    dt:   0.001000\n",
      "\n",
      " Time step    1\n",
      " Time step   20\n",
      " Time step   40\n",
      " Time step   60\n",
      " Time step   80\n",
      " Time step  100\n",
      " Time step  120\n",
      " Time step  140\n",
      " Time step  160\n",
      " Time step  180\n",
      " Time step  200\n",
      " Time step  220\n",
      " Time step  240\n",
      " Time step  260\n",
      " Time step  280\n",
      " Time step  300\n",
      " Time step  320\n",
      " Time step  340\n",
      " Time step  360\n",
      " Time step  380\n",
      " Time step  400\n",
      " Verification being performed for class B\n",
      " accuracy setting for epsilon =  1.0000000000000E-08\n",
      " Comparison of RMS-norms of residual\n",
      "           1 6.9032935799984E+01 6.9032935799980E+01 5.4757737164712E-14\n",
      "           2 3.0951344880843E+01 3.0951344880840E+01 8.6087866920116E-14\n",
      "           3 4.1033366470175E+01 4.1033366470170E+01 1.1203593309142E-13\n",
      "           4 3.8647690096039E+01 3.8647690096040E+01 3.5850999924939E-14\n",
      "           5 5.6434822725956E+01 5.6434822725960E+01 6.3456128951099E-14\n",
      " Comparison of RMS-norms of solution error\n",
      "           1 9.8100061901884E-03 9.8100061901880E-03 4.0494538769611E-14\n",
      "           2 1.0228279056704E-03 1.0228279056700E-03 3.9792568553793E-13\n",
      "           3 1.7205979116917E-03 1.7205979116920E-03 1.5060132147273E-13\n",
      "           4 1.6944794282311E-03 1.6944794282310E-03 8.4715320378331E-14\n",
      "           5 1.8474562639811E-02 1.8474562639810E-02 7.5306152294802E-14\n",
      " Verification Successful\n",
      "\n",
      "\n",
      " SP Benchmark Completed.\n",
      " Class           =                        B\n",
      " Size            =            102x 102x 102\n",
      " Iterations      =                      400\n",
      " Time in seconds =                    35.32\n",
      " Mop/s total     =                     0.00\n",
      " Operation type  =           floating point\n",
      " Verification    =               SUCCESSFUL\n",
      " Version         =                    3.3.1\n",
      " Compile date    =              23 May 2017\n",
      "\n",
      " Compile options:\n",
      "    CC           = (none)\n",
      "    CLINK        = (none)\n",
      "    C_LIB        = -lm\n",
      "    C_INC        = -I../common\n",
      "    CFLAGS       = (none)\n",
      "    CLINKFLAGS   = (none)\n",
      "    RAND         = randdp\n",
      "\n",
      "--------------------------------------\n",
      " Please send all errors/feedbacks to:\n",
      " Center for Manycore Programming\n",
      " cmp@aces.snu.ac.kr\n",
      " http://aces.snu.ac.kr\n",
      "--------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ulimit -s unlimited && ./NPB-acc/SP-step1/sp.B.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's record our results in the table:\n",
    "\n",
    "|Step| Execution    | Time(s)     | Speedup vs. 1 CPU Thread  | Correct? | Programming Time |\n",
    "| -- || ------------ | ----------- | ------------------------- | -------- | ---------------- |\n",
    "|1| CPU 1 thread |554.46      |                           |          | |\n",
    "|2| Add parallel loop  |35.32      | 15.70X           | Yes      | ||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "Compiler use default setting of gang, worker and vector to run the benchmark.\n",
    "We can still adjust these values manully to let the program fit the device you have.\n",
    "\n",
    "For example:\n",
    "```\n",
    "#pragma acc parallel loop gang present(rhs) num_gangs(nz2) num_workers(8) vector_length(32) vector_length(32)\n",
    "    for (k = 1; k <= nz2; k++) {\n",
    "  #pragma acc loop worker\n",
    "    for (j = 1; j <= ny2; j++) {\n",
    "  #pragma acc loop vector\n",
    "      for (i = 1; i <= nx2; i++) {\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f *.x *.o *~ mputil* ../common/*.o *.i *.cu *.ptx *.w2c.c *.w2c.h *.t *.B *.spin\n",
      "rm -f npbparams.h core\n",
      "make[1]: Entering directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "rm -f setparams setparams.h npbparams.h\n",
      "rm -f *~ *.o\n",
      "cc  -o setparams setparams.c\n",
      "make[1]: Leaving directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "../sys/setparams sp B\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 sp.c\n",
      "main:\n",
      "    202, Generating create(forcing[:][:][:][:],qs[:][:][:],rho_i[:][:][:],rhs[:][:][:][:],speed[:][:][:],square[:][:][:],u[:][:][:][:],us[:][:][:],vs[:][:][:],ws[:][:][:])\n",
      "    209, Generating update device(forcing[:][:][:][:])\n",
      "    215, Generating update device(u[:][:][:][:])\n",
      "    219, Generating update device(u[:][:][:][:])\n",
      "    233, Generating update self(u[:][:][:][:])\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 initialize.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 exact_solution.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 exact_rhs.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 set_constants.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 adi.c\n",
      "ninvr:\n",
      "     87, Generating present(rhs[:][:][:][:])\n",
      "     92, Loop is parallelizable\n",
      "     94, Loop is parallelizable\n",
      "     96, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "         92, #pragma acc loop gang /* blockIdx.y */\n",
      "         94, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "         96, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "pinvr:\n",
      "    127, Generating present(rhs[:][:][:][:])\n",
      "    132, Loop is parallelizable\n",
      "    134, Loop is parallelizable\n",
      "    136, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        132, #pragma acc loop gang /* blockIdx.y */\n",
      "        134, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        136, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "tzetar:\n",
      "    168, Generating present(qs[:][:][:],rhs[:][:][:][:],speed[:][:][:],u[:][:][:][:],us[:][:][:],vs[:][:][:],ws[:][:][:])\n",
      "    173, Loop is parallelizable\n",
      "    175, Loop is parallelizable\n",
      "    177, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        173, #pragma acc loop gang /* blockIdx.y */\n",
      "        175, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        177, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "x_solve:\n",
      "    229, Generating create(lhsX[:][:][:][:],lhsmX[:][:][:][:],lhspX[:][:][:][:])\n",
      "         Generating present(rho_i[:][:][:])\n",
      "         Generating create(rhonX[:][:][:],rhsX[:][:][:][:])\n",
      "         Generating present(rhs[:][:][:][:],speed[:][:][:],us[:][:][:])\n",
      "    237, Loop is parallelizable\n",
      "    239, Loop is parallelizable\n",
      "    241, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        237, #pragma acc loop gang /* blockIdx.y */\n",
      "        239, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        241, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    256, Loop is parallelizable\n",
      "    258, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        256, #pragma acc loop gang /* blockIdx.x */\n",
      "        258, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "        259, #pragma acc loop seq\n",
      "    259, Loop is parallelizable\n",
      "    287, Loop is parallelizable\n",
      "    289, Loop is parallelizable\n",
      "    290, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        287, #pragma acc loop gang /* blockIdx.y */\n",
      "        289, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        290, #pragma acc loop gang /* blockIdx.x */\n",
      "    296, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        287, #pragma acc loop gang /* blockIdx.y */\n",
      "        289, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        296, #pragma acc loop gang /* blockIdx.x */\n",
      "    318, Loop is parallelizable\n",
      "    320, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        318, #pragma acc loop gang /* blockIdx.x */\n",
      "        320, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    337, Loop is parallelizable\n",
      "    339, Loop is parallelizable\n",
      "    340, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        337, #pragma acc loop gang /* blockIdx.x */\n",
      "        339, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        340, #pragma acc loop gang /* blockIdx.y */\n",
      "    357, Loop is parallelizable\n",
      "    359, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        357, #pragma acc loop gang /* blockIdx.x */\n",
      "        359, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    380, Loop is parallelizable\n",
      "    382, Loop is parallelizable\n",
      "    384, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        380, #pragma acc loop gang /* blockIdx.y */\n",
      "        382, #pragma acc loop gang, worker(32) /* blockIdx.x threadIdx.x */\n",
      "        384, #pragma acc loop gang, vector(4) /* blockIdx.z threadIdx.y */\n",
      "    411, Loop is parallelizable\n",
      "    413, Loop is parallelizable\n",
      "    414, Loop carried dependence of lhsX,rhsX prevents parallelization\n",
      "         Loop carried backward dependence of lhsX,rhsX prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        411, #pragma acc loop gang /* blockIdx.x */\n",
      "        413, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "        414, #pragma acc loop seq\n",
      "    464, Loop is parallelizable\n",
      "    466, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        464, #pragma acc loop gang /* blockIdx.x */\n",
      "        466, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    511, Loop is parallelizable\n",
      "    513, Loop is parallelizable\n",
      "    514, Loop carried dependence of lhsmX,lhspX,rhsX prevents parallelization\n",
      "         Loop carried backward dependence of lhsmX,lhspX,rhsX prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        511, #pragma acc loop gang /* blockIdx.x */\n",
      "        513, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "        514, #pragma acc loop seq\n",
      "    555, Loop is parallelizable\n",
      "    557, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        555, #pragma acc loop gang /* blockIdx.x */\n",
      "        557, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    595, Loop is parallelizable\n",
      "    597, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        595, #pragma acc loop gang /* blockIdx.x */\n",
      "        597, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    619, Loop is parallelizable\n",
      "    621, Loop is parallelizable\n",
      "    622, Loop carried dependence of rhsX prevents parallelization\n",
      "         Loop carried backward dependence of rhsX prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        619, #pragma acc loop gang /* blockIdx.x */\n",
      "        621, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "        622, #pragma acc loop seq\n",
      "    659, Loop is parallelizable\n",
      "    661, Loop is parallelizable\n",
      "    663, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        659, #pragma acc loop gang /* blockIdx.y */\n",
      "        661, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        663, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "y_solve:\n",
      "    695, Generating create(lhsY[:][:][:][:],lhsmY[:][:][:][:],lhspY[:][:][:][:])\n",
      "         Generating present(rho_i[:][:][:])\n",
      "         Generating create(rhoqY[:][:][:])\n",
      "         Generating present(rhs[:][:][:][:],speed[:][:][:],vs[:][:][:])\n",
      "    702, Loop is parallelizable\n",
      "    704, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        702, #pragma acc loop gang /* blockIdx.x */\n",
      "        704, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "        705, #pragma acc loop seq\n",
      "    705, Loop is parallelizable\n",
      "    734, Loop is parallelizable\n",
      "    736, Loop is parallelizable\n",
      "    737, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        734, #pragma acc loop gang /* blockIdx.x */\n",
      "        736, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        737, #pragma acc loop gang /* blockIdx.y */\n",
      "    743, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        734, #pragma acc loop gang /* blockIdx.x */\n",
      "        736, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        743, #pragma acc loop gang /* blockIdx.y */\n",
      "    764, Loop is parallelizable\n",
      "    766, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        764, #pragma acc loop gang /* blockIdx.x */\n",
      "        766, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    783, Loop is parallelizable\n",
      "    785, Loop is parallelizable\n",
      "    787, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        783, #pragma acc loop gang /* blockIdx.y */\n",
      "        785, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        787, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    803, Loop is parallelizable\n",
      "    805, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        803, #pragma acc loop gang /* blockIdx.x */\n",
      "        805, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    825, Loop is parallelizable\n",
      "    827, Loop is parallelizable\n",
      "    829, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        825, #pragma acc loop gang /* blockIdx.y */\n",
      "        827, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        829, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    853, Loop is parallelizable\n",
      "    855, Loop is parallelizable\n",
      "    856, Loop carried dependence of lhsY,rhs prevents parallelization\n",
      "         Loop carried backward dependence of lhsY,rhs prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        853, #pragma acc loop gang /* blockIdx.x */\n",
      "        855, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "        856, #pragma acc loop seq\n",
      "    907, Loop is parallelizable\n",
      "    909, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        907, #pragma acc loop gang /* blockIdx.x */\n",
      "        909, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    954, Loop is parallelizable\n",
      "    957, Loop is parallelizable\n",
      "    958, Loop carried dependence of lhsmY,lhspY,rhs prevents parallelization\n",
      "         Loop carried backward dependence of lhsmY,lhspY,rhs prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        954, #pragma acc loop gang /* blockIdx.x */\n",
      "        957, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "        958, #pragma acc loop seq\n",
      "    998, Loop is parallelizable\n",
      "   1000, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        998, #pragma acc loop gang /* blockIdx.x */\n",
      "       1000, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "   1038, Loop is parallelizable\n",
      "   1040, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1038, #pragma acc loop gang /* blockIdx.x */\n",
      "       1040, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "       1041, #pragma acc loop seq\n",
      "   1041, Loop is parallelizable\n",
      "   1058, Loop is parallelizable\n",
      "   1060, Loop is parallelizable\n",
      "   1061, Loop carried dependence of rhs prevents parallelization\n",
      "         Loop carried backward dependence of rhs prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1058, #pragma acc loop gang /* blockIdx.x */\n",
      "       1060, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "       1061, #pragma acc loop seq\n",
      "z_solve:\n",
      "   1113, Generating create(lhsZ[:][:][:][:],lhsmZ[:][:][:][:],lhspZ[:][:][:][:])\n",
      "         Generating present(rho_i[:][:][:])\n",
      "         Generating create(rhosZ[:][:][:])\n",
      "         Generating present(rhs[:][:][:][:],speed[:][:][:],ws[:][:][:])\n",
      "   1121, Loop is parallelizable\n",
      "   1123, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1121, #pragma acc loop gang /* blockIdx.x */\n",
      "       1123, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "       1124, #pragma acc loop seq\n",
      "   1124, Loop is parallelizable\n",
      "   1153, Loop is parallelizable\n",
      "   1155, Loop is parallelizable\n",
      "   1157, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1153, #pragma acc loop gang /* blockIdx.y */\n",
      "       1155, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1157, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1170, Loop is parallelizable\n",
      "   1172, Loop is parallelizable\n",
      "   1174, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1170, #pragma acc loop gang /* blockIdx.y */\n",
      "       1172, #pragma acc loop gang, worker(32) /* blockIdx.x threadIdx.x */\n",
      "       1174, #pragma acc loop gang, vector(4) /* blockIdx.z threadIdx.y */\n",
      "   1194, Loop is parallelizable\n",
      "   1196, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1194, #pragma acc loop gang /* blockIdx.x */\n",
      "       1196, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "   1215, Loop is parallelizable\n",
      "   1217, Loop is parallelizable\n",
      "   1219, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1215, #pragma acc loop gang /* blockIdx.y */\n",
      "       1217, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1219, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1234, Loop is parallelizable\n",
      "   1236, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1234, #pragma acc loop gang /* blockIdx.x */\n",
      "       1236, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "   1258, Loop is parallelizable\n",
      "   1260, Loop is parallelizable\n",
      "   1262, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1258, #pragma acc loop gang /* blockIdx.y */\n",
      "       1260, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1262, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1286, Loop is parallelizable\n",
      "   1288, Loop is parallelizable\n",
      "   1289, Loop carried dependence of lhsZ,rhs prevents parallelization\n",
      "         Loop carried backward dependence of lhsZ,rhs prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1286, #pragma acc loop gang /* blockIdx.x */\n",
      "       1288, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "       1289, #pragma acc loop seq\n",
      "   1340, Loop is parallelizable\n",
      "   1342, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1340, #pragma acc loop gang /* blockIdx.x */\n",
      "       1342, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "   1387, Loop is parallelizable\n",
      "   1389, Loop is parallelizable\n",
      "   1390, Loop carried dependence of lhsmZ,lhspZ,rhs prevents parallelization\n",
      "         Loop carried backward dependence of lhsmZ,lhspZ,rhs prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1387, #pragma acc loop gang /* blockIdx.x */\n",
      "       1389, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "       1390, #pragma acc loop seq\n",
      "   1430, Loop is parallelizable\n",
      "   1432, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1430, #pragma acc loop gang /* blockIdx.x */\n",
      "       1432, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "   1471, Loop is parallelizable\n",
      "   1473, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1471, #pragma acc loop gang /* blockIdx.x */\n",
      "       1473, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "   1500, Loop is parallelizable\n",
      "   1502, Loop is parallelizable\n",
      "   1503, Loop carried dependence of rhs prevents parallelization\n",
      "         Loop carried backward dependence of rhs prevents vectorization\n",
      "         Inner sequential loop scheduled on accelerator\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1500, #pragma acc loop gang /* blockIdx.x */\n",
      "       1502, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "       1503, #pragma acc loop seq\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 rhs.c\n",
      "compute_rhs:\n",
      "     77, Generating present(forcing[:][:][:][:],qs[:][:][:],rho_i[:][:][:],rhs[:][:][:][:],speed[:][:][:],square[:][:][:],u[:][:][:][:],us[:][:][:],vs[:][:][:],ws[:][:][:])\n",
      "     85, Loop is parallelizable\n",
      "     87, Loop is parallelizable\n",
      "     89, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "         85, #pragma acc loop gang /* blockIdx.y */\n",
      "         87, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "         89, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    120, Loop is parallelizable\n",
      "    122, Loop is parallelizable\n",
      "    124, Loop is parallelizable\n",
      "    125, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        120, #pragma acc loop gang /* blockIdx.y */\n",
      "        122, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        124, #pragma acc loop vector(32) /* threadIdx.x */\n",
      "        125, #pragma acc loop gang /* blockIdx.z */\n",
      "    140, Loop is parallelizable\n",
      "    142, Loop is parallelizable\n",
      "    144, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        140, #pragma acc loop gang /* blockIdx.y */\n",
      "        142, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        144, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    193, Loop is parallelizable\n",
      "    195, Loop is parallelizable\n",
      "    196, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        193, #pragma acc loop gang /* blockIdx.y */\n",
      "        195, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        196, #pragma acc loop gang /* blockIdx.x */\n",
      "    209, Loop is parallelizable\n",
      "    211, Loop is parallelizable\n",
      "    212, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        209, #pragma acc loop gang /* blockIdx.y */\n",
      "        211, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        212, #pragma acc loop gang /* blockIdx.x */\n",
      "    225, Loop is parallelizable\n",
      "    227, Loop is parallelizable\n",
      "    229, Loop is parallelizable\n",
      "    230, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        225, #pragma acc loop gang /* blockIdx.y */\n",
      "        227, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        229, #pragma acc loop vector(32) /* threadIdx.x */\n",
      "        230, #pragma acc loop gang /* blockIdx.z */\n",
      "    246, Loop is parallelizable\n",
      "    248, Loop is parallelizable\n",
      "    249, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        246, #pragma acc loop gang /* blockIdx.y */\n",
      "        248, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        249, #pragma acc loop gang /* blockIdx.x */\n",
      "    263, Loop is parallelizable\n",
      "    265, Loop is parallelizable\n",
      "    266, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        263, #pragma acc loop gang /* blockIdx.y */\n",
      "        265, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        266, #pragma acc loop gang /* blockIdx.x */\n",
      "    281, Loop is parallelizable\n",
      "    283, Loop is parallelizable\n",
      "    285, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        281, #pragma acc loop gang /* blockIdx.y */\n",
      "        283, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        285, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    334, Loop is parallelizable\n",
      "    336, Loop is parallelizable\n",
      "    337, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        334, #pragma acc loop gang /* blockIdx.x */\n",
      "        336, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        337, #pragma acc loop gang /* blockIdx.y */\n",
      "    350, Loop is parallelizable\n",
      "    352, Loop is parallelizable\n",
      "    353, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        350, #pragma acc loop gang /* blockIdx.x */\n",
      "        352, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        353, #pragma acc loop gang /* blockIdx.y */\n",
      "    366, Loop is parallelizable\n",
      "    368, Loop is parallelizable\n",
      "    370, Loop is parallelizable\n",
      "    371, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        366, #pragma acc loop gang /* blockIdx.y */\n",
      "        368, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        370, #pragma acc loop vector(32) /* threadIdx.x */\n",
      "        371, #pragma acc loop gang /* blockIdx.z */\n",
      "    387, Loop is parallelizable\n",
      "    389, Loop is parallelizable\n",
      "    390, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        387, #pragma acc loop gang /* blockIdx.x */\n",
      "        389, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        390, #pragma acc loop gang /* blockIdx.y */\n",
      "    404, Loop is parallelizable\n",
      "    406, Loop is parallelizable\n",
      "    407, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        404, #pragma acc loop gang /* blockIdx.x */\n",
      "        406, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        407, #pragma acc loop gang /* blockIdx.y */\n",
      "    422, Loop is parallelizable\n",
      "    424, Loop is parallelizable\n",
      "    426, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        422, #pragma acc loop gang /* blockIdx.y */\n",
      "        424, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        426, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    474, Loop is parallelizable\n",
      "    476, Loop is parallelizable\n",
      "    477, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        474, #pragma acc loop gang /* blockIdx.x */\n",
      "        476, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        477, #pragma acc loop gang /* blockIdx.y */\n",
      "    490, Loop is parallelizable\n",
      "    492, Loop is parallelizable\n",
      "    493, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        490, #pragma acc loop gang /* blockIdx.x */\n",
      "        492, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.z threadIdx.y threadIdx.x */\n",
      "        493, #pragma acc loop gang /* blockIdx.y */\n",
      "    506, Loop is parallelizable\n",
      "    508, Loop is parallelizable\n",
      "    510, Loop is parallelizable\n",
      "    511, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        506, #pragma acc loop gang /* blockIdx.y */\n",
      "        508, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        510, #pragma acc loop vector(32) /* threadIdx.x */\n",
      "        511, #pragma acc loop gang /* blockIdx.z */\n",
      "    527, Loop is parallelizable\n",
      "    529, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        527, #pragma acc loop gang /* blockIdx.x */\n",
      "        529, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    561, Loop is parallelizable\n",
      "    563, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        561, #pragma acc loop gang /* blockIdx.x */\n",
      "        563, #pragma acc loop gang, worker(4), vector(32) /* blockIdx.y threadIdx.y threadIdx.x */\n",
      "    588, Loop is parallelizable\n",
      "    590, Loop is parallelizable\n",
      "    592, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        588, #pragma acc loop gang /* blockIdx.y */\n",
      "        590, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        592, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 add.c\n",
      "add:\n",
      "     73, Generating present(rhs[:][:][:][:],u[:][:][:][:])\n",
      "     77, Loop is parallelizable\n",
      "     79, Loop is parallelizable\n",
      "     81, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "         77, #pragma acc loop gang /* blockIdx.y */\n",
      "         79, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "         81, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 txinvr.c\n",
      "txinvr:\n",
      "     74, Generating present(qs[:][:][:],rho_i[:][:][:],rhs[:][:][:][:],speed[:][:][:],us[:][:][:],vs[:][:][:],ws[:][:][:])\n",
      "     78, Loop is parallelizable\n",
      "     80, Loop is parallelizable\n",
      "     82, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "         78, #pragma acc loop gang /* blockIdx.y */\n",
      "         80, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "         82, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 error.c\n",
      "rhs_norm:\n",
      "    115, Generating update self(rhs[:][:][:][:])\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 verify.c\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 print_results.c\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium c_timers.c\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium  -o wtime.o ../common/wtime.c\n",
      "pgcc -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -o ./sp.B.x sp.o initialize.o exact_solution.o exact_rhs.o set_constants.o adi.o rhs.o add.o txinvr.o error.o verify.o print_results.o ../common/c_timers.o ../common/wtime.o  -lm\n"
     ]
    }
   ],
   "source": [
    "!cd ./NPB-acc/SP-final/ && make clean && make CC=pgcc CLASS=B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " NAS Parallel Benchmarks (NPB3.3-ACC) - SP Benchmark\n",
      "\n",
      " No input file inputsp.data. Using compiled defaults\n",
      " Size:  102x 102x 102\n",
      " Iterations:  400    dt:   0.001000\n",
      "\n",
      " Time step    1\n",
      " Time step   20\n",
      " Time step   40\n",
      " Time step   60\n",
      " Time step   80\n",
      " Time step  100\n",
      " Time step  120\n",
      " Time step  140\n",
      " Time step  160\n",
      " Time step  180\n",
      " Time step  200\n",
      " Time step  220\n",
      " Time step  240\n",
      " Time step  260\n",
      " Time step  280\n",
      " Time step  300\n",
      " Time step  320\n",
      " Time step  340\n",
      " Time step  360\n",
      " Time step  380\n",
      " Time step  400\n",
      " Verification being performed for class B\n",
      " accuracy setting for epsilon =  1.0000000000000E-08\n",
      " Comparison of RMS-norms of residual\n",
      "           1 6.9032935799984E+01 6.9032935799980E+01 5.2699175617166E-14\n",
      "           2 3.0951344880843E+01 3.0951344880840E+01 8.5399163984755E-14\n",
      "           3 4.1033366470174E+01 4.1033366470170E+01 1.0597525664907E-13\n",
      "           4 3.8647690096039E+01 3.8647690096040E+01 3.6402553769938E-14\n",
      "           5 5.6434822725956E+01 5.6434822725960E+01 6.5344704217500E-14\n",
      " Comparison of RMS-norms of solution error\n",
      "           1 9.8100061901884E-03 9.8100061901880E-03 4.2616523333957E-14\n",
      "           2 1.0228279056704E-03 1.0228279056700E-03 3.9707768194595E-13\n",
      "           3 1.7205979116917E-03 1.7205979116920E-03 1.5223966220842E-13\n",
      "           4 1.6944794282311E-03 1.6944794282310E-03 7.7677038473787E-14\n",
      "           5 1.8474562639811E-02 1.8474562639810E-02 7.4742764621774E-14\n",
      " Verification Successful\n",
      "\n",
      "\n",
      " SP Benchmark Completed.\n",
      " Class           =                        B\n",
      " Size            =            102x 102x 102\n",
      " Iterations      =                      400\n",
      " Time in seconds =                    12.46\n",
      " Mop/s total     =                     0.00\n",
      " Operation type  =           floating point\n",
      " Verification    =               SUCCESSFUL\n",
      " Version         =                    3.3.1\n",
      " Compile date    =              23 May 2017\n",
      "\n",
      " Compile options:\n",
      "    CC           = (none)\n",
      "    CLINK        = (none)\n",
      "    C_LIB        = -lm\n",
      "    C_INC        = -I../common\n",
      "    CFLAGS       = (none)\n",
      "    CLINKFLAGS   = (none)\n",
      "    RAND         = randdp\n",
      "\n",
      "--------------------------------------\n",
      " Please send all errors/feedbacks to:\n",
      " Center for Manycore Programming\n",
      " cmp@aces.snu.ac.kr\n",
      " http://aces.snu.ac.kr\n",
      "--------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ulimit -s unlimited && ./NPB-acc/SP-final/sp.B.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's record our results in the table:\n",
    "\n",
    "|Step| Execution    | Time(s)     | Speedup vs. 1 CPU Thread  | Correct? | Programming Time |\n",
    "| -- || ------------ | ----------- | ------------------------- | -------- | ---------------- |\n",
    "|1| CPU 1 thread |554.46      |                           |          | |\n",
    "|2| Add parallel loop  |35.32      | 15.70X           | Yes      | |\n",
    "|3| Optimization  |12.46      | 44.50X           | Yes      | ||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We get better performance when the problem size fits block dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
