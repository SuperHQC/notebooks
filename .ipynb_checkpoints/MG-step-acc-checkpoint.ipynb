{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPB-openACC-C-MG Implementation\n",
    "In this self-paced, hands-on lab, we will briefly explore some methods for OpenACC\n",
    "\n",
    "Qichao Hong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Before we begin, let's verify [WebSockets](http://en.wikipedia.org/wiki/WebSocket) are working on your system.  To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see get some output returned below the grey cell.  If not, please consult the [Self-paced Lab Troubleshooting FAQ](https://developer.nvidia.com/self-paced-labs-faq#Troubleshooting) to debug the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer should be three: 3\n"
     ]
    }
   ],
   "source": [
    "print (\"The answer should be three: \" + str(1+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the cell below to get some info about the GPUs on the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 23 06:15:37 2017       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 375.51                 Driver Version: 375.51                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 780 Ti  Off  | 0000:01:00.0     N/A |                  N/A |\r\n",
      "| 26%   36C    P8    N/A /  N/A |    345MiB /  3017MiB |     N/A      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 780 Ti  Off  | 0000:02:00.0     N/A |                  N/A |\r\n",
      "| 26%   36C    P8    N/A /  N/A |      1MiB /  3020MiB |     N/A      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0                  Not Supported                                         |\r\n",
      "|    1                  Not Supported                                         |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU: Intel i7-4960x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<p class=\"hint_trigger\">If you have never before taken an IPython Notebook based self-paced lab from NVIDIA, click this green box.\n",
    "      <div class=\"toggle_container\"><div class=\"input_area box-flex1\"><div class=\\\"highlight\\\">The following video will explain the infrastructure we are using for this self-paced lab, as well as give some tips on it's usage.  If you've never taken a lab on this system before, it's highly encourage you watch this short video first.<br><br>\n",
    "<div align=\"center\"><iframe width=\"640\" height=\"390\" src=\"http://www.youtube.com/embed/ZMrDaLSFqpY\" frameborder=\"0\" allowfullscreen></iframe></div>\n",
    "<br>\n",
    "<h2 style=\"text-align:center;color:red;\">Attention Firefox Users</h2><div style=\"text-align:center; margin: 0px 25px 0px 25px;\">There is a bug with Firefox related to setting focus in any text editors embedded in this lab. Even though the cursor may be blinking in the text editor, focus for the keyboard may not be there, and any keys you press may be applying to the previously selected cell.  To work around this issue, you'll need to first click in the margin of the browser window (where there are no cells) and then in the text editor.  Sorry for this inconvenience, we're working on getting this fixed.</div></div></div></div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to OpenACC\n",
    "\n",
    "Open-specification OpenACC directives are a straightforward way to accelerate existing Fortran and C applications. With OpenACC directives, you provide hints via compiler directives (or 'pragmas') to tell the compiler where -- and how -- it should parallelize compute-intensive code for execution on an accelerator. \n",
    "\n",
    "If you've done parallel programming using OpenMP, OpenACC is very similar: using directives, applications can be parallelized *incrementally*, with little or no change to the Fortran, C or C++ source. Debugging and code maintenance are easier. OpenACC directives are designed for *portability* across operating systems, host CPUs, and accelerators. You can use OpenACC directives with GPU accelerated libraries, explicit parallel programming languages (e.g., CUDA), MPI, and OpenMP, *all in the same program.*\n",
    "\n",
    "Watch the following short video introduction to OpenACC:\n",
    "\n",
    "<div align=\"center\"><iframe width=\"640\" height=\"390\" style=\"margin: 0 auto;\" src=\"http://www.youtube.com/embed/c9WYCFEt_Uo\" frameborder=\"0\" allowfullscreen></iframe></div>\n",
    "\n",
    "This hands-on lab walks you through a short sample of a scientific code, and demonstrates how you can employ OpenACC directives using a four-step process. You will make modifications to a simple C program, then compile and execute the newly enhanced code in each step. Along the way, hints and solution are provided, so you can check your work, or take a peek if you get lost.\n",
    "\n",
    "If you are confused now, or at any point in this lab, you can consult the <a href=\"#FAQ\">FAQ</a> located at the bottom of this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Characterize Your Application\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most difficult part of accelerator programming begins before the first line of code is written. If your program is not highly parallel, an accelerator or coprocesor won't be much use. Understanding the code structure is crucial if you are going to *identify opportunities* and *successfully* parallelize a piece of code. The first step in OpenACC programming then is to *characterize the application*. This includes:\n",
    "\n",
    "+ benchmarking the single-thread, CPU-only version of the application\n",
    "+ understanding the program structure and how data is passed through the call tree\n",
    "+ profiling the application and identifying computationally-intense \"hot spots\"\n",
    "    + which loop nests dominate the runtime?\n",
    "    + what are the minimum/average/maximum tripcounts through these loop nests?\n",
    "    + are the loop nests suitable for an accelerator?\n",
    "+ insuring that the algorithms you are considering for acceleration are *safely* parallel\n",
    "\n",
    "Note: what we've just said may sound a little scary, so please note that as parallel programming methods go OpenACC is really pretty friendly: think of it as a sandbox you can play in. Because OpenACC directives are incremental, you can add one or two directives at a time and see how things work: the compiler provides a *lot* of feedback. The right software plus good tools plus educational experiences like this one should put you on the path to successfully accelerating your programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Profiling and Benchmarking\n",
    "\n",
    "Before you start modifying code and adding OpenACC directives, you should benchmark the serial version of the program. To facilitate benchmarking after this and every other step in our parallel porting effort, we have built a timing routine around the main structure of our program -- a process we recommend you follow in your own efforts. Let's run the `MG` file without making any changes -- and see how fast the serial program executes. This will establish a baseline for future comparisons.  Execute the following two cells to compile and run the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f *.o *~ ../common/*.o *.w2c.c *.w2c.h *.i *.B *.t *.w2c.cu *.w2c.ptx *.spin *.s *.x\n",
      "rm -f npbparams.h core\n",
      "make[1]: Entering directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "rm -f setparams setparams.h npbparams.h\n",
      "rm -f *~ *.o\n",
      "cc  -o setparams setparams.c\n",
      "make[1]: Leaving directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "../sys/setparams mg B\n",
      "cc  -c -I../common  -DCRPL_COMP=0 mg.c\n",
      "cd ../common; cc  -c -I../common  print_results.c\n",
      "cd ../common; cc  -c -I../common  c_timers.c\n",
      "cd ../common; cc  -c -I../common   -o wtime.o ../common/wtime.c\n",
      "cd ../common; cc  -c -I../common  randdp.c\n",
      "cc  -o ./mg.B.x mg.o ../common/print_results.o ../common/c_timers.o ../common/wtime.o ../common/randdp.o -lm\n"
     ]
    }
   ],
   "source": [
    "!cd ./NPB-acc/MG-seq/ && make clean && make MG CLASS=B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " NAS Parallel Benchmarks (NPB3.3-SER-C) - MG Benchmark\n",
      "\n",
      " No input file. Using compiled defaults \n",
      " Size:  256x 256x 256  (class B)\n",
      " Iterations:  20\n",
      "\n",
      " Initialization time:           3.743 seconds\n",
      "\n",
      "  iter   1\n",
      "  iter   5\n",
      "  iter  10\n",
      "  iter  15\n",
      "  iter  20\n",
      "\n",
      " Benchmark completed\n",
      " VERIFICATION SUCCESSFUL\n",
      " L2 Norm is  1.8005644013551E-06\n",
      " Error is    6.6330115975290E-14\n",
      "\n",
      "\n",
      " MG Benchmark Completed.\n",
      " Class           =                        B\n",
      " Size            =            256x 256x 256\n",
      " Iterations      =                       20\n",
      " Time in seconds =                    28.04\n",
      " Mop/s total     =                   694.11\n",
      " Operation type  =           floating point\n",
      " Verification    =               SUCCESSFUL\n",
      " Version         =                    3.3.1\n",
      " Compile date    =              23 May 2017\n",
      "\n",
      " Compile options:\n",
      "    CC           = (none)\n",
      "    CLINK        = (none)\n",
      "    C_LIB        = -lm\n",
      "    C_INC        = -I../common\n",
      "    CFLAGS       = (none)\n",
      "    CLINKFLAGS   = (none)\n",
      "    RAND         = randdp\n",
      "\n",
      "--------------------------------------\n",
      " Please send all errors/feedbacks to:\n",
      " Center for Manycore Programming\n",
      " cmp@aces.snu.ac.kr\n",
      " http://aces.snu.ac.kr\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "======== CPU profiling result (top down):\n",
      "Time(%)      Time  Name\n",
      " 100.00%    31.78s  main\n",
      " 68.31%    21.71s    mg3P\n",
      " 28.54%     9.07s    | psinv\n",
      "  0.28%      90ms    | | comm3\n",
      " 25.52%     8.11s    | resid\n",
      "  0.41%     130ms    | | comm3\n",
      "  7.74%     2.46s    | interp\n",
      "  6.04%     1.92s    | rprj3\n",
      "  0.09%      30ms    | | comm3\n",
      "  0.47%     150ms    | zero3\n",
      " 24.29%     7.72s    resid\n",
      "  0.22%      70ms    | comm3\n",
      "  4.85%     1.54s    zran3\n",
      "  3.87%     1.23s    | vranlc\n",
      "  0.28%      90ms    | zero3\n",
      "  0.06%      20ms    | comm3\n",
      "  0.03%      10ms    | randlc\n",
      "  2.27%     720ms    norm2u3\n",
      "  0.94%     300ms    | pow\n",
      "  0.50%     160ms    | | ???\n",
      "  0.06%      20ms    | ???\n",
      "  0.28%      90ms    zero3\n",
      "\n",
      "======== Data collected at 100Hz frequency\n"
     ]
    }
   ],
   "source": [
    "!pgprof --cpu-profiling on --cpu-profiling-mode top-down ./NPB-acc/MG-seq/mg.B.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Checking/Keeping a Record\n",
    "\n",
    "*After each step*, we will record the results from our benchmarking and correctness tests in a table like this one: \n",
    "\n",
    "|Step| Execution       | ExecutionTime (s)     | Speedup vs. 1 CPU Thread       | Correct? | Programming Time |\n",
    "|:--:| --------------- | ---------------------:| ------------------------------:|:--------:| -----------------|\n",
    "|1   | CPU 1 thread    | 28.04           |                                | Yes      |                |  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see mg3P(), resid(), psinv(), interp(), rprj3() need the most time to compute. So we will work mainly on these functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Add Compute Directives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things need to to before you add #pragma ...\n",
    "    1. Initiate the GPU\n",
    "        acc_init(acc_device_default);\n",
    "    2. Create the variables on GPU needed to run\n",
    "        #pragma acc data create(u[0:gnr],v[0:gnr],r[0:gnr])\n",
    "        {\n",
    "            ...\n",
    "         }\n",
    "    3. Tell the GPU where the data is using deviceptr()\n",
    "        #pragma acc data deviceptr(r1,r2) present(ou[0:n3*n2*n1]) present(or[0:n3*n2*n1])\n",
    "        {\n",
    "        ...\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In psinv(), initiate r1 and r2 by acc malloc\n",
    "    Using #pragma acc data deviceptr(r1,r2) to tell GPU the address\n",
    "    \n",
    "In resid(), initiate u1 and u2 by acc_malloc\n",
    "    using #pragma acc data deviceptr() to pass to GPU\n",
    "    \n",
    "In rprj3(), initiate x1 and y1 by acc_malloc\n",
    "    using #pragma acc data deviceptr() to pass to GPU\n",
    "    \n",
    "In interp(), ~~ z1, z2 and z3 by ~~\n",
    "    Using deviceptr()\n",
    "\n",
    "In zero3(), after it finishing, update oz[] on device\n",
    "\n",
    "    \n",
    "Add '#pragma acc parallel loop' to all nesty for loops\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f *.o *~ ../common/*.o *.w2c.c *.w2c.h *.i *.B *.t *.w2c.cu *.w2c.ptx *.spin *.s *.x\n",
      "rm -f npbparams.h core\n",
      "make[1]: Entering directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "rm -f setparams setparams.h npbparams.h\n",
      "rm -f *~ *.o\n",
      "cc  -o setparams setparams.c\n",
      "make[1]: Leaving directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "../sys/setparams mg B\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 mg.c\n",
      "main:\n",
      "    248, Generating create(r[:gnr],u[:gnr],v[:gnr])\n",
      "psinv:\n",
      "    530, Generating present(or[:n1*(n2*n3)],ou[:n1*(n2*n3)])\n",
      "    534, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        535, #pragma acc loop gang /* blockIdx.x */\n",
      "        536, #pragma acc loop seq\n",
      "        537, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    536, Loop carried dependence of r1->,r2-> prevents parallelization\n",
      "         Loop carried backward dependence of r1->,r2-> prevents vectorization\n",
      "    537, Loop is parallelizable\n",
      "    553, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        554, #pragma acc loop gang /* blockIdx.x */\n",
      "        555, #pragma acc loop seq\n",
      "        556, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    555, Loop carried dependence of ou-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "    556, Loop is parallelizable\n",
      "resid:\n",
      "    649, Generating present(or[:n1*(n2*n3)],ou[:n1*(n2*n3)],ov[:n1*(n2*n3)])\n",
      "    654, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        657, #pragma acc loop gang /* blockIdx.x */\n",
      "        658, #pragma acc loop seq\n",
      "        659, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "    658, Loop carried dependence of u1->,u2-> prevents parallelization\n",
      "         Loop carried backward dependence of u1->,u2-> prevents vectorization\n",
      "    659, Loop is parallelizable\n",
      "    676, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        679, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "        680, #pragma acc loop seq\n",
      "        681, #pragma acc loop seq\n",
      "    680, Loop carried dependence of or-> prevents parallelization\n",
      "         Complex loop carried dependence of or->,ou->,ov-> prevents parallelization\n",
      "         Loop carried backward dependence of or-> prevents vectorization\n",
      "    681, Complex loop carried dependence of or->,ou->,ov-> prevents parallelization\n",
      "rprj3:\n",
      "    780, Generating present(or[:m1k*(m2k*m3k)],os[:m1j*(m2j*m3j)])\n",
      "    785, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        786, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "        788, #pragma acc loop seq\n",
      "        790, #pragma acc loop seq\n",
      "    788, Complex loop carried dependence of or->,x1->,y1-> prevents parallelization\n",
      "         Loop carried reuse of x1->,y1-> prevents parallelization\n",
      "    790, Complex loop carried dependence of or->,x1->,y1-> prevents parallelization\n",
      "         Loop carried reuse of x1->,y1-> prevents parallelization\n",
      "    807, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        808, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "        810, #pragma acc loop seq\n",
      "        812, #pragma acc loop seq\n",
      "    810, Loop carried dependence of os-> prevents parallelization\n",
      "         Complex loop carried dependence of or->,os->,x1->,y1-> prevents parallelization\n",
      "         Loop carried backward dependence of os-> prevents vectorization\n",
      "    812, Complex loop carried dependence of or->,os->,x1->,y1-> prevents parallelization\n",
      "interp:\n",
      "    904, Generating present(ou[:n1*(n2*n3)],oz[:mm1*(mm2*mm3)])\n",
      "    911, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        912, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "        913, #pragma acc loop seq\n",
      "        914, #pragma acc loop seq\n",
      "    913, Loop carried dependence of z1->,z2->,z3-> prevents parallelization\n",
      "         Complex loop carried dependence of oz->,z1->,z2->,z3-> prevents parallelization\n",
      "         Loop carried backward dependence of z1->,z2->,z3-> prevents vectorization\n",
      "         Loop carried dependence of z1-> prevents vectorization\n",
      "    914, Complex loop carried dependence of oz->,z1->,z2->,z3-> prevents parallelization\n",
      "    932, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        933, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "        934, #pragma acc loop seq\n",
      "        935, #pragma acc loop seq\n",
      "    934, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "         Loop carried dependence of ou-> prevents vectorization\n",
      "    935, Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "    951, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        952, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "        953, #pragma acc loop seq\n",
      "        954, #pragma acc loop seq\n",
      "    953, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,z1-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "         Loop carried dependence of ou-> prevents vectorization\n",
      "    954, Complex loop carried dependence of ou->,z1-> prevents parallelization\n",
      "    970, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        971, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "        972, #pragma acc loop seq\n",
      "        973, #pragma acc loop seq\n",
      "    972, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,z2-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "         Loop carried dependence of ou-> prevents vectorization\n",
      "    973, Complex loop carried dependence of ou->,z2-> prevents parallelization\n",
      "    989, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        990, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "        991, #pragma acc loop seq\n",
      "        992, #pragma acc loop seq\n",
      "    991, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,z3-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "         Loop carried dependence of ou-> prevents vectorization\n",
      "    992, Complex loop carried dependence of ou->,z3-> prevents parallelization\n",
      "   1032, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1033, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1034, #pragma acc loop seq\n",
      "       1035, #pragma acc loop seq\n",
      "   1034, Loop carried dependence of ou-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1035, Loop carried dependence of ou-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1048, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1049, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1050, #pragma acc loop seq\n",
      "       1051, #pragma acc loop seq\n",
      "   1050, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1051, Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "   1065, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1066, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1067, #pragma acc loop seq\n",
      "       1068, #pragma acc loop seq\n",
      "   1067, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1068, Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "   1082, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1083, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1084, #pragma acc loop seq\n",
      "       1085, #pragma acc loop seq\n",
      "   1084, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1085, Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "   1102, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1103, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1104, #pragma acc loop seq\n",
      "       1105, #pragma acc loop seq\n",
      "   1104, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1105, Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "   1119, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1120, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1121, #pragma acc loop seq\n",
      "       1122, #pragma acc loop seq\n",
      "   1121, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1122, Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "   1139, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1140, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1141, #pragma acc loop seq\n",
      "       1142, #pragma acc loop seq\n",
      "   1141, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1142, Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "   1159, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1160, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1161, #pragma acc loop seq\n",
      "       1162, #pragma acc loop seq\n",
      "   1161, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1162, Complex loop carried dependence of ou->,oz-> prevents parallelization\n",
      "norm2u3:\n",
      "   1240, Generating copyin(or[:n1*(n2*n3)])\n",
      "   1243, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1243, Generating reduction(+:s)\n",
      "             Generating reduction(max:temp)\n",
      "       1244, #pragma acc loop gang /* blockIdx.x */\n",
      "       1245, #pragma acc loop seq\n",
      "       1246, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1245, Loop is parallelizable\n",
      "   1246, Loop is parallelizable\n",
      "comm3:\n",
      "   1284, Generating present(ou[:n1*(n2*n3)])\n",
      "   1287, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1288, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1289, #pragma acc loop seq\n",
      "   1289, Loop carried dependence of ou-> prevents parallelization\n",
      "         Complex loop carried dependence of ou-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1299, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1300, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1301, #pragma acc loop seq\n",
      "   1301, Loop carried dependence of ou-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "   1311, Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1312, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */\n",
      "       1313, #pragma acc loop seq\n",
      "   1313, Loop carried dependence of ou-> prevents parallelization\n",
      "         Loop carried backward dependence of ou-> prevents vectorization\n",
      "zran3:\n",
      "   1589, Generating update device(oz[:n1*(n2*n3)])\n",
      "zero3:\n",
      "   1712, Generating present(oz[:n1*(n2*n3)])\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1715, #pragma acc loop gang /* blockIdx.x */\n",
      "       1716, #pragma acc loop seq\n",
      "       1717, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "   1716, Loop carried dependence of oz-> prevents parallelization\n",
      "         Loop carried backward dependence of oz-> prevents vectorization\n",
      "   1717, Loop is parallelizable\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium print_results.c\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium c_timers.c\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium  -o wtime.o ../common/wtime.c\n",
      "pgcc -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -o ./mg.B.x mg.o ../common/print_results.o ../common/c_timers.o ../common/wtime.o -lm\n"
     ]
    }
   ],
   "source": [
    "!cd ./NPB-acc/MG-step1/ && make clean && make CC=pgcc CLASS=B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get any error please check your work and try re-compilling.\n",
    "\n",
    "### We can see the detials about how compiler handle the loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " NAS Parallel Benchmarks (NPB3.3-ACC-C) - MG Benchmark\n",
      "\n",
      " No input file. Using compiled defaults \n",
      " Size:  256x 256x 256  (class B)\n",
      " Iterations:  20\n",
      "\n",
      " Initialization time:           1.879 seconds\n",
      "\n",
      "  iter   1\n",
      "  iter  20\n",
      "\n",
      " Benchmark completed\n",
      " VERIFICATION SUCCESSFUL\n",
      " L2 Norm is  1.8005644013552E-06\n",
      " Error is    9.4202877475545E-14\n",
      "\n",
      "\n",
      " MG Benchmark Completed.\n",
      " Class           =                        B\n",
      " Size            =            256x 256x 256\n",
      " Iterations      =                       20\n",
      " Time in seconds =                    16.18\n",
      " Mop/s total     =                  1202.48\n",
      " Operation type  =           floating point\n",
      " Verification    =               SUCCESSFUL\n",
      " Version         =                    3.3.1\n",
      " Compile date    =              23 May 2017\n",
      "\n",
      " Compile options:\n",
      "    CC           = (none)\n",
      "    CLINK        = (none)\n",
      "    C_LIB        = -lm\n",
      "    C_INC        = -I../common\n",
      "    CFLAGS       = (none)\n",
      "    CLINKFLAGS   = (none)\n",
      "    RAND         = randdp\n",
      "\n",
      "--------------------------------------\n",
      " Please send all errors/feedbacks to:\n",
      " Center for Manycore Programming\n",
      " cmp@aces.snu.ac.kr\n",
      " http://aces.snu.ac.kr\n",
      "--------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./NPB-acc/MG-step1/mg.B.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's record our results in the table:\n",
    "\n",
    "|Step| Execution    | Time(s)     | Speedup vs. 1 CPU Thread  | Correct? | Programming Time |\n",
    "| -- || ------------ | ----------- | ------------------------- | -------- | ---------------- |\n",
    "|1| CPU 1 thread |28.04      |                           |          | |\n",
    "|2| Add parallel loop  |16.18      | 1.73X           | Yes      | ||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "Compiler use default setting of gang, worker and vector to run the benchmark.\n",
    "We can still adjust these values manully to let the program fit the device you have.\n",
    "\n",
    "For example:\n",
    "```\n",
    "#pragma acc parallel loop gang num_gangs(n3-2) num_workers(16) vector_length(64)\n",
    "    for (i3 = 1; i3 < n3-1; i3++) {\n",
    "#pragma acc loop worker\n",
    "      for (i2 = 1; i2 < n2-1; i2++) {\n",
    "#pragma acc loop vector\n",
    "        for (i1 = 0; i1 < n1; i1++) {\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f *.o *~ ../common/*.o *.w2c.c *.w2c.h *.i *.B *.t *.w2c.cu *.w2c.ptx *.spin *.s *.x\n",
      "rm -f npbparams.h core\n",
      "make[1]: Entering directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "rm -f setparams setparams.h npbparams.h\n",
      "rm -f *~ *.o\n",
      "cc  -o setparams setparams.c\n",
      "make[1]: Leaving directory '/home/qichao/Desktop/notebooks-acc/NPB-acc/sys'\n",
      "../sys/setparams mg B\n",
      "pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -DCRPL_COMP=0 mg.c\n",
      "main:\n",
      "    248, Generating create(r[:gnr],u[:gnr],v[:gnr])\n",
      "psinv:\n",
      "    530, Generating present(or[:n1*(n2*n3)],ou[:n1*(n2*n3)])\n",
      "    539, Loop is parallelizable\n",
      "    541, Loop is parallelizable\n",
      "    543, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        539, #pragma acc loop gang /* blockIdx.y */\n",
      "        541, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        543, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    564, Loop is parallelizable\n",
      "    566, Loop is parallelizable\n",
      "    568, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        564, #pragma acc loop gang /* blockIdx.y */\n",
      "        566, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        568, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "resid:\n",
      "    661, Generating present(or[:n1*(n2*n3)],ou[:n1*(n2*n3)],ov[:n1*(n2*n3)])\n",
      "    673, Loop is parallelizable\n",
      "    675, Loop is parallelizable\n",
      "    677, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        673, #pragma acc loop gang /* blockIdx.y */\n",
      "        675, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        677, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    701, Loop is parallelizable\n",
      "    703, Loop is parallelizable\n",
      "    705, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        701, #pragma acc loop gang /* blockIdx.y */\n",
      "        703, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        705, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "rprj3:\n",
      "    804, Generating present(or[:m1k*(m2k*m3k)],os[:m1j*(m2j*m3j)])\n",
      "    814, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        814, #pragma acc loop gang /* blockIdx.x */\n",
      "        817, #pragma acc loop worker(4) /* threadIdx.y */\n",
      "        818, Vector barrier inserted due to potential dependence into a vector loop\n",
      "        820, #pragma acc loop vector(32) /* threadIdx.x */\n",
      "    817, Loop is parallelizable\n",
      "    820, Loop is parallelizable\n",
      "    842, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        842, #pragma acc loop gang /* blockIdx.x */\n",
      "        845, #pragma acc loop worker(4) /* threadIdx.y */\n",
      "        846, Vector barrier inserted due to potential dependence into a vector loop\n",
      "        848, #pragma acc loop vector(32) /* threadIdx.x */\n",
      "    845, Loop is parallelizable\n",
      "    848, Loop is parallelizable\n",
      "interp:\n",
      "    940, Generating present(ou[:n1*(n2*n3)],oz[:mm1*(mm2*mm3)])\n",
      "    952, Loop is parallelizable\n",
      "    954, Loop is parallelizable\n",
      "    956, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        952, #pragma acc loop gang /* blockIdx.y */\n",
      "        954, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        956, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "    979, Loop is parallelizable\n",
      "    981, Loop is parallelizable\n",
      "    983, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "        979, #pragma acc loop gang /* blockIdx.y */\n",
      "        981, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "        983, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1004, Loop is parallelizable\n",
      "   1006, Loop is parallelizable\n",
      "   1008, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1004, #pragma acc loop gang /* blockIdx.y */\n",
      "       1006, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1008, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1029, Loop is parallelizable\n",
      "   1031, Loop is parallelizable\n",
      "   1033, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1029, #pragma acc loop gang /* blockIdx.y */\n",
      "       1031, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1033, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1054, Loop is parallelizable\n",
      "   1056, Loop is parallelizable\n",
      "   1058, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1054, #pragma acc loop gang /* blockIdx.y */\n",
      "       1056, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1058, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1103, Loop is parallelizable\n",
      "   1105, Loop is parallelizable\n",
      "   1107, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1103, #pragma acc loop gang /* blockIdx.y */\n",
      "       1105, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1107, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1125, Loop is parallelizable\n",
      "   1127, Loop is parallelizable\n",
      "   1129, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1125, #pragma acc loop gang /* blockIdx.y */\n",
      "       1127, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1129, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1148, Loop is parallelizable\n",
      "   1150, Loop is parallelizable\n",
      "   1152, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1148, #pragma acc loop gang /* blockIdx.y */\n",
      "       1150, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1152, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1171, Loop is parallelizable\n",
      "   1173, Loop is parallelizable\n",
      "   1175, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1171, #pragma acc loop gang /* blockIdx.y */\n",
      "       1173, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1175, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1197, Loop is parallelizable\n",
      "   1199, Loop is parallelizable\n",
      "   1201, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1197, #pragma acc loop gang /* blockIdx.y */\n",
      "       1199, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1201, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1220, Loop is parallelizable\n",
      "   1222, Loop is parallelizable\n",
      "   1224, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1220, #pragma acc loop gang /* blockIdx.y */\n",
      "       1222, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1224, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1246, Loop is parallelizable\n",
      "   1248, Loop is parallelizable\n",
      "   1250, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1246, #pragma acc loop gang /* blockIdx.y */\n",
      "       1248, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1250, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "   1272, Loop is parallelizable\n",
      "   1274, Loop is parallelizable\n",
      "   1276, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1272, #pragma acc loop gang /* blockIdx.y */\n",
      "       1274, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1276, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "norm2u3:\n",
      "   1354, Generating copyin(or[:n1*(n2*n3)])\n",
      "   1363, Loop is parallelizable\n",
      "   1365, Loop is parallelizable\n",
      "   1367, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1363, #pragma acc loop gang /* blockIdx.y */\n",
      "       1365, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1367, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "             Generating reduction(+:s)\n",
      "             Generating reduction(max:temp)\n",
      "comm3:\n",
      "   1405, Generating present(ou[:n1*(n2*n3)])\n",
      "   1413, Loop is parallelizable\n",
      "   1415, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1413, #pragma acc loop gang, vector(4) /* blockIdx.y threadIdx.y */\n",
      "       1415, #pragma acc loop gang, vector(32) /* blockIdx.x threadIdx.x */\n",
      "   1430, Loop is parallelizable\n",
      "   1432, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1430, #pragma acc loop gang, vector(4) /* blockIdx.y threadIdx.y */\n",
      "       1432, #pragma acc loop gang, vector(32) /* blockIdx.x threadIdx.x */\n",
      "   1447, Loop is parallelizable\n",
      "   1449, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1447, #pragma acc loop gang, vector(4) /* blockIdx.y threadIdx.y */\n",
      "       1449, #pragma acc loop gang, vector(32) /* blockIdx.x threadIdx.x */\n",
      "zran3:\n",
      "   1725, Generating update device(oz[:n1*(n2*n3)])\n",
      "zero3:\n",
      "   1851, Generating present(oz[:n1*(n2*n3)])\n",
      "   1855, Loop is parallelizable\n",
      "   1857, Loop is parallelizable\n",
      "   1859, Loop is parallelizable\n",
      "         Accelerator kernel generated\n",
      "         Generating Tesla code\n",
      "       1855, #pragma acc loop gang /* blockIdx.y */\n",
      "       1857, #pragma acc loop gang, worker(4) /* blockIdx.x threadIdx.y */\n",
      "       1859, #pragma acc loop gang, vector(32) /* blockIdx.z threadIdx.x */\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium print_results.c\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium c_timers.c\n",
      "cd ../common; pgcc  -c -I../common -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium  -o wtime.o ../common/wtime.c\n",
      "pgcc -O3 -acc -ta=nvidia,cc35,cuda8.0  -Minfo=accel -mcmodel=medium -o ./mg.B.x mg.o ../common/print_results.o ../common/c_timers.o ../common/wtime.o -lm\n"
     ]
    }
   ],
   "source": [
    "!cd ./NPB-acc/MG-final/ && make clean && make CC=pgcc CLASS=B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " NAS Parallel Benchmarks (NPB3.3-ACC-C) - MG Benchmark\n",
      "\n",
      " No input file. Using compiled defaults \n",
      " Size:  256x 256x 256  (class B)\n",
      " Iterations:  20\n",
      "\n",
      " Initialization time:           0.948 seconds\n",
      "\n",
      "  iter   1\n",
      "  iter  20\n",
      "\n",
      " Benchmark completed\n",
      " VERIFICATION SUCCESSFUL\n",
      " L2 Norm is  1.8005644013552E-06\n",
      " Error is    9.4202877475545E-14\n",
      "\n",
      "\n",
      " MG Benchmark Completed.\n",
      " Class           =                        B\n",
      " Size            =            256x 256x 256\n",
      " Iterations      =                       20\n",
      " Time in seconds =                     0.58\n",
      " Mop/s total     =                 33454.47\n",
      " Operation type  =           floating point\n",
      " Verification    =               SUCCESSFUL\n",
      " Version         =                    3.3.1\n",
      " Compile date    =              23 May 2017\n",
      "\n",
      " Compile options:\n",
      "    CC           = (none)\n",
      "    CLINK        = (none)\n",
      "    C_LIB        = -lm\n",
      "    C_INC        = -I../common\n",
      "    CFLAGS       = (none)\n",
      "    CLINKFLAGS   = (none)\n",
      "    RAND         = randdp\n",
      "\n",
      "--------------------------------------\n",
      " Please send all errors/feedbacks to:\n",
      " Center for Manycore Programming\n",
      " cmp@aces.snu.ac.kr\n",
      " http://aces.snu.ac.kr\n",
      "--------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./NPB-acc/MG-final/mg.B.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's record our results in the table:\n",
    "\n",
    "|Step| Execution    | Time(s)     | Speedup vs. 1 CPU Thread  | Correct? | Programming Time |\n",
    "| -- || ------------ | ----------- | ------------------------- | -------- | ---------------- |\n",
    "|1| CPU 1 thread |28.04      |                           |          | |\n",
    "|2| Add parallel loop  |16.18      | 1.73X           | Yes      | |\n",
    "|3| Optimization  |0.58      | 48.43X           | Yes      | ||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Input will have different result\n",
    "### No idea why it speed up only 1.73x by default configuration of block dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
